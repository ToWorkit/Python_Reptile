{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    segment\n",
      "2        首映\n",
      "3        整部\n",
      "4        片子\n",
      "5        感觉\n",
      "7        侮辱\n",
      "8        观众\n",
      "9        智商\n",
      "11      反抗军\n",
      "14        做\n",
      "15       不到\n",
      "18      想不到\n",
      "20       帝国\n",
      "21        军\n",
      "24       简直\n",
      "26        人\n",
      "27       怀疑\n",
      "32       统治\n",
      "33       宇宙\n",
      "35      天行者\n",
      "37      本索罗\n",
      "40       决战\n",
      "41       竟然\n",
      "44       全息\n",
      "45       投影\n",
      "47        真\n",
      "49      本索罗\n",
      "51       一个\n",
      "52      最不像\n",
      "53      领导者\n",
      "55        人\n",
      "..      ...\n",
      "856     迪士尼\n",
      "858      星戰\n",
      "861      最弱\n",
      "863      一部\n",
      "864      片長\n",
      "865      雖長\n",
      "867      文戲\n",
      "868       拍\n",
      "870      不算\n",
      "871      理想\n",
      "874     師徒關\n",
      "875       係\n",
      "876       略\n",
      "877       為\n",
      "878      單薄\n",
      "879      部份\n",
      "880      枝節\n",
      "882      顯得\n",
      "883      無謂\n",
      "884       後\n",
      "885       段\n",
      "887      凌厲\n",
      "889      特別\n",
      "891    壓軸一場\n",
      "893       人\n",
      "894      拍案\n",
      "896      絕惟\n",
      "897      整體\n",
      "899       太\n",
      "900      理想\n",
      "\n",
      "[577 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "headers = {\n",
    "  'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8',\n",
    "  'Accept-Encoding': 'gzip, deflate, br',\n",
    "  'Accept-Language': 'zh-CN,zh;q=0.9',\n",
    "  'Upgrade-Insecure-Requests': '1',\n",
    "  'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.84 Safari/537.36',\n",
    "}\n",
    "\n",
    "''' 获取电影信息 '''\n",
    "def get_movie_details():\n",
    "  url = 'https://movie.douban.com/cinema/nowplaying/beijing/'\n",
    "  # 构建请求并接收响应\n",
    "  response = requests.get(url=url, headers=headers)\n",
    "  response.encoding = 'utf-8'\n",
    "  # print(response.text)\n",
    "  html_data = response.text\n",
    "  # 构建BeautifulSoup对象\n",
    "  soup_obj = bs(html_data, 'html.parser') \n",
    "  # 找到正在上映的电影信息标签 -> list格式\n",
    "  nowplaying_movie = soup_obj.find_all('div', id='nowplaying')\n",
    "  # print(nowplaying_movie)\n",
    "  # 找到电影信息列表的li\n",
    "  nowplaying_movie_list = nowplaying_movie[0].find_all('li', class_='list-item')\n",
    "  # 获取电影id，根据电影图片获取电影名称\n",
    "  # print(nowplaying_movie_list)\n",
    "  nowplaying_list = []\n",
    "  for item in nowplaying_movie_list:\n",
    "    # print(item['data-actors'])\n",
    "    # print(item)\n",
    "    nowplaying_dict = {}\n",
    "    nowplaying_dict['id'] = item['data-subject']\n",
    "    for tag_img_item in item.find_all('img'):\n",
    "      nowplaying_dict['name'] = tag_img_item['alt']\n",
    "      nowplaying_list.append(nowplaying_dict)\n",
    "  return nowplaying_list\n",
    "\n",
    "''' 获取电影评论信息 '''\n",
    "def get_movie_comment():\n",
    "  movie_id = get_movie_details()[0]['id']\n",
    "  url = 'https://movie.douban.com/subject/' + movie_id + '/comments?start=0&limit=20'\n",
    "  response = requests.get(url=url, headers=headers)\n",
    "  response.encoding = 'utf-8'\n",
    "  html_data = response.text\n",
    "  # 构建BeautifulSoup对象\n",
    "  soup_obj = bs(html_data, 'html.parser')\n",
    "  # 找到评论标签\n",
    "  comment_conent = soup_obj.find_all('div', class_='comment')\n",
    "  # 获取到评论内容\n",
    "  eachCommentList = []\n",
    "  for item in comment_conent:\n",
    "    # find_all -> list\n",
    "    if item.find_all('p')[0].string is not None:\n",
    "      eachCommentList.append(item.find_all('p')[0].string)\n",
    "  return eachCommentList\n",
    "\n",
    "\n",
    "''' 数据清洗 '''\n",
    "def data_cleaning():\n",
    "  comments = ''\n",
    "  comment_data = get_movie_comment()\n",
    "  for k in range(len(comment_data)):\n",
    "    comments = comments + (str(comment_data[k])).strip()\n",
    "  # 去掉标点符号\n",
    "  pattern = re.compile(r'[\\u4e00-\\u9fa5]+')\n",
    "  filter_data = re.findall(pattern, comments)\n",
    "  # 清洗后的数据\n",
    "  cleaned_comments = ''.join(filter_data)\n",
    "  return cleaned_comments\n",
    "\n",
    "# 结巴分词\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "# 分割 -> 直接返回 list\n",
    "segment = jieba.lcut(data_cleaning())\n",
    "# 生成表格\n",
    "words_df = pd.DataFrame({'segment': segment})\n",
    "# 去除停用词(高频出现的词)\n",
    "# https://www.cnblogs.com/datablog/p/6127000.html -> 参数说明\n",
    "stopwords = pd.read_csv('StopWords.txt', index_col=False, quoting=3, sep=\"\\t\", names=['stopword'], encoding='utf-8')\n",
    "words_df = words_df[~words_df.segment.isin(stopwords.stopword)]\n",
    "print(words_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
